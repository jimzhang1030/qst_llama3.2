#!/usr/bin/env python3
"""
QST GLUE Benchmark - å®Œæ•´ç‰ˆ
è‡ªåŠ¨æ”¶é›†ç»Ÿè®¡æ•°æ®å¹¶å¯¼å‡ºåˆ°Excel
"""

import sys
import os

# é¦–å…ˆå¯¼å…¥train_qst_with_statsä¸­çš„å‡½æ•°
exec(open('train_qst_with_stats.py').read().split('if __name__')[0])

import pandas as pd
from datetime import datetime
import argparse

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="QST GLUE Benchmark with Excel Export")
    parser.add_argument("--task", type=str, default=None, help="è¿è¡Œå•ä¸ªä»»åŠ¡ï¼Œæˆ–ä¸æŒ‡å®šåˆ™è¿è¡Œæ‰€æœ‰ä»»åŠ¡")
    parser.add_argument("--epochs", type=int, default=None, help="è¦†ç›–é»˜è®¤epochs")
    args = parser.parse_args()
    
    # ä»»åŠ¡åˆ—è¡¨
    if args.task:
        tasks = [args.task]
    else:
        # é»˜è®¤è¿è¡Œæ‰€æœ‰8ä¸ªGLUEä»»åŠ¡
        tasks = ["rte", "mrpc", "stsb", "cola", "sst2", "qnli", "qqp", "mnli"]
    
    parameters = {
        "model_checkpoint": "meta-llama/Llama-3.2-1B",
        "batch_size": 8,
        "max_len": 128,
        "epochs": args.epochs if args.epochs else 3,
        "r": 16,
        "alpha_r": 16,
    }
    
    results = {}
    print(f"\nğŸš€ å¼€å§‹è¿è¡Œ {len(tasks)} ä¸ªGLUEä»»åŠ¡...")
    print("="*60)
    
    for idx, task in enumerate(tasks, 1):
        print(f"\n[{idx}/{len(tasks)}] å½“å‰ä»»åŠ¡: {task.upper()}")
        try:
            metrics = train_qst_model(task, parameters)
            results[task] = metrics
            print(f"âœ… {task.upper()} å®Œæˆ - å‡†ç¡®ç‡: {metrics.get('eval_accuracy', 0)*100:.2f}%")
        except Exception as e:
            print(f"âŒ {task.upper()} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("è®­ç»ƒå®Œæˆ! ç»“æœæ±‡æ€»:")
    print("="*60)
    
    excel_data = []
    for task, result in results.items():
        print(f"\n{task.upper()}:")
        for metric, value in result.items():
            if isinstance(value, (int, float)):
                print(f"  {metric}: {value:.4f}")
        
        # æ”¶é›†Excelæ•°æ®
        row = {
            'ä»»åŠ¡': task.upper(),
            'æœ€ä½³å‡†ç¡®ç‡(%)': result.get('eval_accuracy', result.get('eval_pearson', 0)) * 100,
            'å¯è®­ç»ƒå‚æ•°å æ¯”(%)': result.get('trainable_ratio', 0),
            'æ˜¾å­˜å³°å€¼(GB)': result.get('peak_memory_gb', 0),
            'æ€»å‚æ•°': result.get('total_params', 0),
            'å¯è®­ç»ƒå‚æ•°': result.get('trainable_params', 0),
            'Loss': result.get('eval_loss', 0),
        }
        if 'eval_f1' in result:
            row['F1'] = result['eval_f1']
        if 'eval_matthews_correlation' in result:
            row['Matthewsç›¸å…³ç³»æ•°'] = result['eval_matthews_correlation']
        if 'eval_pearson' in result:
            row['Pearsonç›¸å…³ç³»æ•°'] = result['eval_pearson']
        if 'eval_spearmanr' in result:
            row['Spearmanç›¸å…³ç³»æ•°'] = result['eval_spearmanr']
        excel_data.append(row)
    
    # å¯¼å‡ºåˆ°Excel
    if excel_data:
        df = pd.DataFrame(excel_data)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"QST_GLUE_Results_{timestamp}.xlsx"
        df.to_excel(filename, index=False, engine='openpyxl')
        
        print(f"\n{'='*60}")
        print(f"âœ… ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")
        print(f"{'='*60}")
        print(f"\nğŸ“Š ç»Ÿè®¡æ±‡æ€»:")
        print(f"  å®Œæˆä»»åŠ¡æ•°: {len(df)}")
        print(f"  å¹³å‡å‡†ç¡®ç‡: {df['æœ€ä½³å‡†ç¡®ç‡(%)'].mean():.2f}%")
        print(f"  å¹³å‡å¯è®­ç»ƒå‚æ•°å æ¯”: {df['å¯è®­ç»ƒå‚æ•°å æ¯”(%)'].mean():.4f}%")
        print(f"  å¹³å‡æ˜¾å­˜å³°å€¼: {df['æ˜¾å­˜å³°å€¼(GB)'].mean():.2f} GB")
        print(f"  æœ€å¤§æ˜¾å­˜å³°å€¼: {df['æ˜¾å­˜å³°å€¼(GB)'].max():.2f} GB")
        print("\nè¯¦ç»†è¡¨æ ¼:")
        print(df[['ä»»åŠ¡', 'æœ€ä½³å‡†ç¡®ç‡(%)', 'å¯è®­ç»ƒå‚æ•°å æ¯”(%)', 'æ˜¾å­˜å³°å€¼(GB)']].to_string(index=False))

